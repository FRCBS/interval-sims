---
title: "eba_sims_data"
author: "Esa Turkulainen"
date: "1/13/2020"
output: pdf_document
---

```{r setup, echo = FALSE}
setwd("~/interval-sims/src")
library(ggplot2)
library(plotly)
library(gridExtra)
library(knitr)
library(dplyr)
library(plyr)
library(lubridate)
library(numbers)
library(data.table)
library(R.utils)
library(forecast)
source("pffunctions.R")
source("helper_functions.R")
```

```{r load_data, echo = FALSE}
load("~/eba_sims/data/20191211CollectionAmounts.rdata")
```

## Inspect data
```{r inspect}
summary(donation10)
```

```{r filtering_function, echo = FALSE}
# Let's build a tool to filter quickly as we please
# TODO: Let the user select multiple levels for each factor
filter_donations <- function(data, 
                             donor=NULL, donation13=NULL, site=NULL,
                             date=NULL, phleb_start=NULL, status=NULL,
                             donat_phleb=NULL, Hb=NULL, gender=NULL,
                             dob=NULL, aborh=NULL, age=NULL,
                             agegroup=NULL, Hb_deferral=NULL){
  temp <- data
  if(!is.null(donor)){
    temp <- temp[temp$donor==donor,]
  }
  if(!is.null(donation13)){
    temp <- temp[temp$donation13==donation13,]
  }
  if(!is.null(site)){
    temp <- temp[temp$site==site,]
  }
  if(!is.null(date)){
    temp <- temp[temp$date > date[1] & temp$date < date[1],]
  }
  if(!is.null(phleb_start)){
    temp <- temp[temp$phleb_start==phleb_start,]
  }
  if(!is.null(status)){
    temp <- temp[temp$status==status,]
  }
  if(!is.null(donat_phleb)){
    temp <- temp[temp$donat_phleb==donat_phleb,]
  }
  if(!is.null(Hb)){
    temp <- temp[temp$Hb > Hb[1] & temp$Hb < Hb[2],]
  }
  if(!is.null(gender)){
    temp <- temp[temp$gender==gender,]
  }
  if(!is.null(site)){
    temp <- temp[temp$site==site,]
  }
  if(!is.null(dob)){
    temp <- temp[temp$dob > dob[1] & temp$dob < dob[2],]
  }
  if(!is.null(aborh)){
    temp <- temp[temp$aborh==aborh,]
  }
  if(!is.null(age)){
    temp <- temp[temp$age > age[1] & temp$age < age[2],]
  }
  if(!is.null(agegroup)){
    temp <- temp[temp$agegroup==agegroup,]
  }
  if(!is.null(Hb_deferral)){
    temp <- temp[temp$Hb_deferral==Hb_deferral,]
  }
  
  return(temp)
}
```

```{r filter_test}
# Only donat_phleb="K" and status="-"
dons <- filter_donations(data = donation10, donat_phleb = "K", status = "-")

```

```{r distribution_of_event_counts}
eventcounts <- table(dons$donor)
hist(eventcounts)
```
Sanity check: passed. (60 is the maximum number of donations in 10 years time)


```{r}
head(dons)
```


```{r}
# Order donations by date
dons <- dons[with(dons, order(date)), ]

# Transform dates to yearweeks
dons$date <- yearweek(dons$date)

# Extract first time donations
firsts <- dons[!duplicated(dons$donor),]
```

```{r}
# Check
firsts[1:20,]
```

```{r}
# Attempting vectorization of the processes below

# Firsts
first_count <- as.data.frame(table(factor(firsts$date, levels=unique(firsts$date))))
# (We needed to call factor() to retain the chronological order of the rows)
colnames(first_count) <- c("week", "firsts")

# All
all_count <- as.data.frame(table(factor(dons$date, levels=unique(dons$date))))
colnames(all_count) <- c("week", "all")
```

```{r}
# Combine into one neat df
counts_df <- data.frame(week=first_count$week, 
                        first=first_count$firsts, 
                        all=all_count$all)
```

```{r}
# Plot
ggplot(data = counts_df, aes(x=week, y=first)) + 
  geom_point(color = "dark red") +
  geom_point(aes(x=week, y=all), color = "pink") +
  theme(axis.text.x = element_text(angle = 45)) +
  geom_abline(intercept = mean(counts_df[158:520,2]), slope=0) +
  geom_abline(intercept = mean(counts_df[158:520,3]), slope=0) +
  scale_x_discrete(breaks=c("2010.1", "2011.1", "2012.1", "2013.1", "2014.1", "2015.1", "2016.1", "2017.1", "2018.1", "2019.1")) +
  theme_bw() +
  labs(title = "Number of weekly first time donations vs. all donations",
       subtitle = paste0("Each week around ", round(mean(counts_df[158:520,2])/mean(counts_df[158:520,3])*100, 2), "%", " of all donations comprise first time donors (2013 onwards)."),
       x = "Weeks",
       y = "Count") +
  annotate(geom="text", 
           x="2019.1", 
           y=mean(counts_df[158:520,2])+400, 
           label=paste0("Firsts: ", round(mean(counts_df[158:520,2]), 1))) +
  annotate(geom="text",
           x="2019.1",
           y=mean(counts_df[158:520,3])+400, 
           label=paste0("All: ", round(mean(counts_df[158:520,3]), 1)))
```

## Cost analysis

```{r}
actual.deferral.rate <- 76565/2464190
```

```{r savings effect, echo = FALSE}
p <- actual.deferral.rate
response.rate <- 1 - 1/10  # 10 invites -> 1 donor
invite.price <- 0.5  # Guess
deferral.price <- 30  # Guesstimate
savings <- savings_effect(p, response.rate, invite.price, deferral.price)

# Alternative p for comparison
p2 <- 0.1
alt.p <- savings_effect(p2, response.rate, invite.price, deferral.price)
```

```{r plot savings}
savings.df <- data.frame(savings = savings, alt = alt.p)
p <- ggplot(data = savings.df, aes(x = seq(0, 100, 1), y = -1*savings, color = "savings")) + 
  geom_line() +
  geom_line(aes(x = seq(0, 100, 1), y = -1*alt.p, color = "alt.p")) +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(title = "Savings as a function of True Positive Rate",
       subtitle = "p = 0.031 and p = 0.1, response.rate = 0.9, invite.price = 0.5, deferral.price = 30",
       y = "Savings (â‚¬)",
       x = "TPR") +
  geom_text(aes(x = 100, y = 0.9, label = "p = 0.031", color = "savings")) +
  geom_text(aes(x = 100, y = 3.5, label = "p = 0.1", color = "alt.p"))
  
p
```


```{r deprecated_roc_space, include = FALSE}
# DEPRECATED!!! WORKS BUT IS INCORRECT. DO NOT USE.
p <- 0.031
price_ratio <- 13.683
surface <- cost_surface(p, price_ratio)
plot_surface(surface, price_ratio, p)
plot_interactive_surface(surface)
```

# Storage level simulation
```{r storage level}
# Create "pool series" based on the following "selections"
# We designate 5 different levels for donation intervals to approximate personalized donation intervals
# This is a "male pool" in that we set the intervals at 30, 40, 60, 70 and 90 days (below and above the current)
# We guess that those interval categories appear at rates 8, 12, 50, 20 and 10 percent
# We run the series for 1 year (365 days)
# We have a pool of 1000 invitees
# To simplify, it is furthermore assumed that invites are sent with 100% response rate at earliest eligibility

pool.series <- generate_pool_series(5, c(0.08, 0.12, 0.5, 0.20, 0.10), 1000, 365, c(30, 40, 60, 70, 90))
# TODO: Non-discretize the above (build on distributions)

# Let's simulate a 1000 realities with these parameters and find the worst case scenario
realities.matrix <- matrix(, nrow = 1000, ncol = 365)
for(i in 1:1000){
  pool.series <- generate_pool_series(5, c(0.08, 0.12, 0.5, 0.20, 0.10), 1000, 365, c(30, 40, 60, 70, 90))
  series <- colSums(pool.series)
  realities.matrix[i, ] <- series
}

# Find worst cases
worsts <- c()
for(i in 1:1000){
  worst <- min(realities.matrix[i, ][90:365])
  worsts <- c(worsts, worst)
}
```

