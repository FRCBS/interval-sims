---
title: "Current model cost effect"
author: "Esa Turkulainen & Mikko Arvas"
date: "`r Sys.time()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
#setwd("~/interval-sims/src")
library(tidyverse)
library(truncnorm)
library(caret)
library(boot)
source("helper_functions.R")
set.seed(123)
#echo "rmarkdown::render('current_model_effect.Rmd', clean=TRUE,output_format='pdf_document',output_file='../results/current_model_effect.pdf')" | R --slave
```

# Calculate parameters from donation history data

```{r load_data, echo = FALSE}
load("..//data/20191211CollectionAmounts.rdata")
```

The data object donation10 contains donation history data from beginning of 2010 to end of 2019. It has the following columns.


```{r }
lapply(donation10,class)
```



## Create subgroups from donation data
```{r subgroups}
# All successful whole blood donations
dons <- filter_donations(data = donation10, donat_phleb = "K", status = "-")
# Order donations by date
dons <- dons[with(dons, order(date)), ]
# Find only returning donors
rdons <- dons[duplicated(dons$donor),]

# Successful male
mdon <- filter_donations(data = rdons, donat_phleb = "K", status = "-", gender = "Men")
# Successful female
fdon <- filter_donations(data = rdons, donat_phleb = "K", status = "-", gender = "Women")
# Deferrals
def <- filter_donations(data = donation10, donat_phleb = "*", Hb_deferral = 1)
mdef <- filter_donations(data = def, gender = "Men")
fdef <- filter_donations(data = def, gender = "Women")

# Windows
walldons <- subset(dons, date >= "2018-01-01" & date <= "2019-12-30")
wdons <- subset(rdons, date >= "2018-01-01" & date <= "2019-12-30")
wmdon <- subset(mdon, date >= "2018-01-01" & date <= "2019-12-30")
wfdon <- subset(fdon, date >= "2018-01-01" & date <= "2019-12-30")
wdef <- subset(def, date >= "2018-01-01" & date <= "2019-12-30")
wmdef <- subset(mdef, date >= "2018-01-01" & date <= "2019-12-30")
wfdef <- subset(fdef, date >= "2018-01-01" & date <= "2019-12-30")
```

## Find ratios from data
```{r}
# Male ratio
mr <- nrow(wmdon)/nrow(wdons)
# Female ratio
fr <- nrow(wfdon)/nrow(wdons)
# Male deferral ratio
mdr <- nrow(wmdef) / nrow(wdef)
# Female deferral ratio
fdr <- nrow(wfdef) / nrow(wdef)
# Total deferral prevalence
d <- nrow(wdef)/(nrow(wdef) + nrow(walldons))
mr
fr
mdr
fdr
d
```

# Find interval adjustments from ratios and model metrics

The current model finds in validation data 1662/2116 = 78.5% of deferrals. In addition, it misclassifies 22.4% of donations as deferrals.
```{r}
# > conf
# Confusion Matrix and Statistics
# 
#           Reference
# Prediction Accepted Deferred
#   Accepted    31719      454
#   Deferred     9137     1662
TPR <- 1662/(1662 + 454) #78.5%
FPR <- 9137 / (31719 + 9137) # 22.4%
# Find q
q <- d * TPR
# Find a for 6 month category
# correctly predicted non-deferrals: 78.5% of the returning donations (all - d): (0.785 * (1 - d))
# incorrectly predicted non-deferrals: 22.4% of the returning donations (all - d): (0.224 * (1 - d))
a6 <- 1 * ((1 - FPR) * (1 - d)) + 
  3 * mr * (FPR * (1 - d)) + 2 * fr * (FPR * (1 - d)) + 
  3 * mdr * d + 2 * fdr * d

a12 <- 1 * ((1 - FPR) * (1 - d)) + 
  6 * mr * (FPR * (1 - d)) + 4 * fr * (FPR * (1 - d)) + 
  6 * mdr * d + 4 * fdr * d
TPR
FPR
a6
a12
```

# Final cost
```{r}
Pm <- 2 # estimate collected from FRCBS experts
Pd <- 60 # estimate collected from FRCBS experts
rl <- 0 # estimated previously from data
Fn = 0.1066 # estimated from donation history data in here https://github.com/FRCBS/interval-sims/blob/master/src/eba_sims_w_data.Rmd 

# a6
Fratio <- a6 / (1 + Fn * (a6 - 1))
Em <- Pm * (Fratio - 1 - q * rl)
Ed <- Pd * q
E6 <- Em - Ed

# a12
Fratio <- a12 / (1 + Fn * (a12 - 1))
Em <- Pm * (Fratio - 1 - q * rl)
Ed <- Pd * q
E12 <- Em - Ed
```

```{r}
E6
E12
q
```


# Plot final cost on data surface

```{r}

q.seq <- seq(0, 0.032, 0.032/1000)
adjustments <- seq(1, 2, 1/1000)
E.matrix <- matrix(nrow = 1001, ncol = 1001)
Fn = 0.1066 # 
for(i in 1:1001){
  Fratio <- adjustments[i] / (1 + Fn * (adjustments[i] - 1))
  for(j in 1:1001){
    Em <- Pm * (Fratio - 1 - q.seq[j] * rl)
    Ed <- Pd * q.seq[j]
    E.matrix[i, j] <- Em - Ed
    }
}

E.long <- reshape2::melt(E.matrix)

```

```{r}
colnames(E.long) <- c("adjustment", "q", "cost")
ggplot(E.long, aes(x = q, y = adjustment, z = cost)) +
geom_tile(aes(fill=cost)) +
  stat_contour(color = "white", size = 0.7, bins = 2) +
  scale_fill_gradientn(colours=c("blue", "red")) +
labs(x="q%", y="Adjustment", title="Cost surface (2018-2020)", subtitle = paste0("Surface minimum: ", round(min(E.long$cost), 2), ". Cost effect thresholds highlighted at 0 and -1 euros.", "\n", "Dots mark current model performance with a 6 or 12 month extension strategy.")) + 
  annotate("point", x = head(which(q.seq > q ),1), y = which(adjustments > a6 & adjustments < (a6 + 0.001)), colour = "white", size = 2, alpha = 1) +
  annotate("point", x = head(which(q.seq > q ),1), y = which(adjustments > a12 & adjustments < (a12 + 0.001)), colour = "white", size = 2, alpha = 1) +
  annotate("text", x = head(which(q.seq > q ),1) - 40 , y = which(adjustments > a6 & adjustments < (a6 + 0.001)), label = "6", colour = "white") +
  annotate("text", x = head(which(q.seq > q ),1) -40, y = which(adjustments > a12 & adjustments < (a12 + 0.001)), label = "12", colour = "white") +
theme_bw() +
scale_x_continuous(breaks = c(1, 1001), labels = c("0", "3.2")) +
scale_y_continuous(breaks = c(1, 1001), labels = c(as.character(min(adjustments)), as.character(max(adjustments))))
ggsave(filename="../results/cme_cost_surface.pdf",  width = 180,  height = 120,units="mm", dpi=600, scale=1.0)
```


# What if we use some other than the default cut-off for model class assingment

```{r}
#Load a data frame with observed classes and probability of deferral from  a classifier
load("../data//rrfFit_roc_validate_probs.rdata")
summary(df)
```

## Create different cuts

```{r}
#cut prediction.probs with seq(0, 1, .1)
x <- seq(0.1, .9, .1)
pred.classes <- data.frame(matrix(nrow=nrow(df),ncol=length(x)))
colnames(pred.classes) <- paste0("p_",x)
for (i in x ) {
  pred.classes[,paste0("p_",i)] <-  factor( df$Deferred >= i ,labels = c("Accepted","Deferred"))
}

head(pred.classes)
```

```{r}
summary(pred.classes)
```

# Count TPR and FPR for each probability cut-off

```{r}

sen <- vector()
spe <- vector()

for(i in names(pred.classes)) {
  conf <- caret::confusionMatrix(reference=df$obs, data=pred.classes[,i], positive = "Deferred",mode="everything")
  #Sensitivity  = TPR
  sen <- c(sen,conf$byClass['Sensitivity']) 
#   > conf$table
#           Reference
# Prediction Accepted Deferred
#   Accepted    31719      454
#   Deferred     9137     1662
# > conf$table[2,1] / (conf$table[1,1] + conf$table[2,1])
# [1] 0.2236391
# > 1- conf$byClass['Specificity'] 
# Specificity 
#   0.2236391 
  spe <- c(spe,1- conf$byClass['Specificity']) 
  
}
tprs <- tibble(probability = x,TPR=sen,FPR=spe)
tprs
```




```{r}


get_cost <- function(TPR, FPR,d.=d, mr.=mr,fr.=fr,mdr.=mdr,fdr.=fdr,Pm.=Pm,Pd.=Pd,Fn.=Fn,rl.=rl) {
  q <- d * TPR
  a6 <- 1 * ((1 - FPR) * (1 - d.)) + 
    3 * mr. * (FPR * (1 - d.)) + 2 * fr. * (FPR * (1 - d.)) + 
    3 * mdr. * d. + 2 * fdr. * d.
  
  a12 <- 1 * ((1 - FPR) * (1 - d.)) + 
    6 * mr. * (FPR * (1 - d.)) + 4 * fr. * (FPR * (1 - d.)) + 
    6 * mdr. * d. + 4 * fdr. * d.
  
  # a6
  Fratio <- a6 / (1 + Fn. * (a6 - 1))
  Em <- Pm. * (Fratio - 1 - q * rl.)
  Ed <- Pd. * q
  E6 <- Em - Ed
  
  # a12
  Fratio <- a12 / (1 + Fn. * (a12 - 1))
  Em <- Pm. * (Fratio - 1 - q * rl.)
  Ed <- Pd. * q
  E12 <- Em - Ed
  tibble(q=q,a6=a6,a12=a12,E6=E6,E12=E12)
}

#Do we get the same as before
# > get_cost(TPR=1662/2116, FPR=9137 / (31719 + 9137),d.=d, mr.=mr,fr.=fr,mdr.=mdr,fdr.=fdr,Pm.=Pm,Pd.=Pd,Fn.=Fn,rl.=rl) 
# # A tibble: 1 x 5
#        q    a6   a12     E6    E12
#    <dbl> <dbl> <dbl>  <dbl>  <dbl>
# 1 0.0257  1.36  1.97 -0.923 0.0256
#Yes


tprs <- tprs %>% group_by(probability,TPR,FPR) %>%  do(get_cost(.$TPR,.$FPR) )

tprs
```

## Plot effect of probability cut-offs

```{r , warning=FALSE}

tprs.plot <- tprs %>% ungroup() %>% select(probability,E6,E12) %>% pivot_longer(cols=c(E6,E12)) %>% mutate(name=gsub("^E",'',name))

size <- 2
p <- ggplot(tprs.plot)
p <- p + geom_line(aes(x=probability,y=value,col=name)) + ylab("Cost effect (€ / donation)") + xlab("Probability of deferral cut-off") + labs(color="Deferral length (mo)")
p <- p + geom_point(aes( y =tprs$E6[which(tprs$E6 == min(tprs$E6))] , x = tprs$probability[which(tprs$E6 == min(tprs$E6))] ))
p <- p + geom_label(aes( y =tprs$E6[which(tprs$E6 == min(tprs$E6))] , x = tprs$probability[which(tprs$E6 == min(tprs$E6))] , label = paste0("p>=",round(tprs$probability[which(tprs$E6 == min(tprs$E6))],2) , " ; ",  round(tprs$E6[which(tprs$E6 == min(tprs$E6))],2)," €")), nudge_y=0.2,size=size)
p <- p + geom_point(aes( y =tprs$E12[which(tprs$E12 == min(tprs$E12))] , x = tprs$probability[which(tprs$E12 == min(tprs$E12))] ))
p <- p + geom_label(aes( y =tprs$E12[which(tprs$E12 == min(tprs$E12))] , x = tprs$probability[which(tprs$E12 == min(tprs$E12))] , label = paste0("p>=",round(tprs$probability[which(tprs$E12 == min(tprs$E12))],2) , " ; ",  round(tprs$E12[which(tprs$E12 == min(tprs$E12))],2)," €")), nudge_y=0.2,size=size)
p <- p + theme(legend.position="bottom")
p
ggsave(filename="../results/cme_prob_cut_curve.pdf", p, width = 90,  height = 80,units="mm", dpi=600, scale=1.0,encoding = "ISOLatin9.enc")
```


Using a bit higher than the default cut-off  appears slightly better.

# Bootstrap cost confidence intervals

Let's bootstrap predictions to create error estimates for the predictions and subsequently on the cost effects.

```{r}
#Define functions
#boot code from https://github.com/FRCBS/changes_in_donor_health/blob/master/src/hypothesis_regressions.Rmd
boot_cost <- function(boot_data, boot_ind, prob.cut = 0.6){
  #sample
    boot_data <- boot_data[boot_ind,]
  #classify predictions
    pred.class <- factor( boot_data$Deferred >= prob.cut)
    levels(pred.class ) <- c("Accepted","Deferred")
  #get TPR and FPR
    conf <- caret::confusionMatrix(reference=boot_data$obs, data=pred.class, positive = "Deferred",mode="sens_spec")
    sen <- conf$byClass['Sensitivity'] 
    spe <- 1- conf$byClass['Specificity'] 
  #get cost
#    cat(sen,spe,"\n")
     c <- get_cost(TPR=sen, FPR=spe,d.=d, mr.=mr,fr.=fr,mdr.=mdr,fdr.=fdr,Pm.=Pm,Pd.=Pd,Fn.=Fn,rl.=rl)
     c <- as.vector(t(c))
     names(c) <- c('q','a6','a12','E6','E12')
  return(c)
}

compute_CI <-function(fit_boot){
  CI_inf = rep(0, length(fit_boot$t0))
  CI_sup = rep(0, length(fit_boot$t0))
  for (i_regressor in 1:length(fit_boot$t0)){
    #https://stackoverflow.com/questions/6791290/r-boot-package-not-enough-memory-to-get-confidence-intervals
    #CI <- boot.ci(fit_boot, type = "bca", index=i_regressor)
    #Bca_inf[i_regressor] <- CI$bca[4] # N.B type = 'normal' has 3 columns, while the other types 5 columns
    #Bca_sup[i_regressor] <- CI$bca[5] #
    #there is just too much data for bca to be used
    CI <- boot.ci(fit_boot, type = "norm", index=i_regressor)
    CI_inf[i_regressor] <- CI$normal[2]
    CI_sup[i_regressor] <- CI$normal[3]
  }
  return(tibble(variable = names(fit_boot$t0),CI_inf,CI_sup))
}
```


```{r}

#nb_boot <- 1000
nb_boot <- nrow(df)
fit_boot <- boot(df,prob.cut=0.6, statistic= boot_cost, R = nb_boot)
p6.ci <- compute_CI(fit_boot)

fit_boot <- boot(df,prob.cut=0.8, statistic= boot_cost, R = nb_boot)
p8.ci <- compute_CI(fit_boot)

p6.ci
```



```{r}
p8.ci
```

## Plot surface with confidence intervals

```{r ,warning=FALSE}
#Get the a (y) and q (x) mappings for the optimised 6 and 12 month scenarios
x6 <- head(which(q.seq > tprs$q[which(tprs$E6 == min(tprs$E6))] ),1)
y6 <- head(which(adjustments > tprs$a6[which(tprs$E6 == min(tprs$E6))]),1)
x12 <- head(which(q.seq > tprs$q[which(tprs$E12 == min(tprs$E12))] ),1)
y12 <- head(which(adjustments > tprs$a12[which(tprs$E12 == min(tprs$E12))]),1)
#Plot them
colnames(E.long) <- c("adjustment", "q", "cost")
p <- ggplot(E.long, aes(x = q, y = adjustment, z = cost)) +
  geom_tile(aes(fill=cost)) +
  stat_contour(color = "white", size = 0.7, binwidth =  1) +
  scale_fill_gradientn(colours=c("blue", "red")) +
  labs(x="q% i.e. rate of avoided deferrals", y=expression(a[tot]~i.e.~donation~interval~coefficient ))  + 
  theme_bw() +
  scale_x_continuous(breaks = c(1, 1001), labels = c("0", "3.2")) +
  scale_y_continuous(breaks = c(1, 1001), labels = c(as.character(min(adjustments)), as.character(max(adjustments))))
#Add numeric values of costs with optimised classifier probability cut-offs
p <- p + annotate("text" ,
                  x = x6 , 
                  y = y6 - 50,
                  label = paste0("6 mo: ", round(tprs$E6[which(tprs$E6 == min(tprs$E6))],2),' (',round(deframe(p6.ci[4,2]),2)," - ",round(deframe(p6.ci[4,3]),2),') €'  ),
                  colour = "white")

p <- p + annotate("text" ,
                  x = x12 , 
                  y = y12 - 50,
                  label = paste0("12 mo: ", round(tprs$E12[which(tprs$E12 == min(tprs$E12))],2),' (',round(deframe(p8.ci[5,2]),2)," - ",round(deframe(p8.ci[5,3]),2),') €'  ),
                  colour = "white")
#Add points estimates
p <- p + annotate("point", x = x6, y = y6, colour = "white", size = 3, alpha = 1) 
p <- p +  annotate("point", x = x12, y = y12, colour = "white", size = 3, alpha = 1) 


#Get x and y values for error bars
xmin.p6  <- head(which(q.seq >  deframe(p6.ci[1,'CI_inf'])) ,1) 
xmax.p6  <- head(which(q.seq >  deframe(p6.ci[1,'CI_sup'])) ,1) 
ymin.p6  <- head(which(adjustments >  deframe(p6.ci[2,'CI_inf'])) ,1) 
ymax.p6  <- head(which(adjustments >  deframe(p6.ci[2,'CI_sup'])) ,1) 

xmin.p12  <- head(which(q.seq >  deframe(p8.ci[1,'CI_inf'])) ,1) 
xmax.p12  <- head(which(q.seq >  deframe(p8.ci[1,'CI_sup'])) ,1) 
ymin.p12  <- head(which(adjustments >  deframe(p8.ci[3,'CI_inf'])) ,1) 
ymax.p12  <- head(which(adjustments >  deframe(p8.ci[3,'CI_sup'])) ,1) 
#Add error bars of q and a

p <- p + annotate("errorbar",x=x6,ymin = ymin.p6, ymax= ymax.p6,size=1   )
p <- p + annotate("errorbarh",y=y6,xmin = xmin.p6, xmax= xmax.p6,size=1   )

p <- p + annotate("errorbar",x=x12,ymin = ymin.p12, ymax= ymax.p12,size=1  )
p <- p + annotate("errorbarh",y=y12,xmin = xmin.p12, xmax= xmax.p12,size=1   )

p <- p + labs(fill="Cost effect (€ / donation)")  + theme(legend.position="bottom")
p
ggsave(filename="../results/cme_cost_surface_werr.pdf",  width = 180,  height = 120,units="mm", dpi=600, scale=1.0,encoding = "ISOLatin9.enc")
```


